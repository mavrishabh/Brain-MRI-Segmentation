{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Conv2DTranspose, Concatenate, Input, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG19, ResNet50V2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFM(low_level_features, high_level_features, num_filters):\n",
    "    # Upsampling\n",
    "    high_level_upsampled = UpSampling2D(size=(2, 2))(high_level_features)\n",
    "    high_level_upsampled = Conv2D(num_filters, (3, 3), padding=\"same\")(high_level_upsampled)\n",
    "    high_level_upsampled = BatchNormalization()(high_level_upsampled)\n",
    "    high_level_upsampled = Activation(\"relu\")(high_level_upsampled)\n",
    "\n",
    "    # Perform 1x1 convolution on low-level features\n",
    "    low_level_processed = Conv2D(num_filters, (1, 1), padding=\"same\")(low_level_features)\n",
    "    low_level_processed = BatchNormalization()(low_level_processed)\n",
    "    low_level_processed = Activation(\"relu\")(low_level_processed)\n",
    "\n",
    "    # Combine low-level and high-level features\n",
    "    combined = Concatenate()([low_level_processed, high_level_upsampled])\n",
    "    \n",
    "    # Fuse features\n",
    "    fused = Conv2D(num_filters, (1, 1), padding=\"same\")(combined)\n",
    "    fused = BatchNormalization()(fused)\n",
    "    fused = Activation(\"relu\")(fused)\n",
    "\n",
    "    return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "def train_df(tr_path):\n",
    "    classes, class_paths = zip(*[(label, os.path.join(tr_path, label, image))\n",
    "                                 for label in os.listdir(tr_path) if os.path.isdir(os.path.join(tr_path, label))\n",
    "                                 for image in os.listdir(os.path.join(tr_path, label))])\n",
    "    tr_df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n",
    "    return tr_df\n",
    "\n",
    "# Load testing data\n",
    "def test_df(ts_path):\n",
    "    classes, class_paths = zip(*[(label, os.path.join(ts_path, label, image))\n",
    "                                 for label in os.listdir(ts_path) if os.path.isdir(os.path.join(ts_path, label))\n",
    "                                 for image in os.listdir(os.path.join(ts_path, label))])\n",
    "    ts_df = pd.DataFrame({'Class Path': class_paths, 'Class': classes})\n",
    "    return ts_df\n",
    "\n",
    "# Loading training and testing data\n",
    "tr_df = train_df('Training')\n",
    "ts_df = test_df('Testing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training data class distribution\n",
    "plt.figure(figsize=(15,7))\n",
    "ax = sns.countplot(data=tr_df, y=tr_df['Class'])\n",
    "plt.title('Count of images in each class', fontsize=20)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()\n",
    "\n",
    "# Visualize testing data class distribution\n",
    "plt.figure(figsize=(15, 7))\n",
    "ax = sns.countplot(y=ts_df['Class'], palette='viridis')\n",
    "ax.set(title='Count of images in each class')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df, ts_df = train_test_split(ts_df, train_size=0.5, random_state=20, stratify=ts_df['Class'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = (256, 256)\n",
    "\n",
    "# Train data augmentation\n",
    "_gen = ImageDataGenerator(rescale=1/255, brightness_range=(0.8, 1.2))\n",
    "ts_gen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow images from the DataFrame\n",
    "tr_gen = _gen.flow_from_dataframe(tr_df, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n",
    "valid_gen = _gen.flow_from_dataframe(valid_df, x_col='Class Path', y_col='Class', batch_size=batch_size, target_size=img_size)\n",
    "ts_gen = ts_gen.flow_from_dataframe(ts_df, x_col='Class Path', y_col='Class', batch_size=16, target_size=img_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = tr_gen.class_indices\n",
    "classes = list(class_dict.keys())\n",
    "images, labels = next(ts_gen)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i, (image, label) in enumerate(zip(images, labels)):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(image)\n",
    "    class_name = classes[np.argmax(label)]\n",
    "    plt.title(class_name, color='k', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg19_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "\n",
    "    s1 = vgg19.get_layer(\"block1_conv2\").output\n",
    "    s2 = vgg19.get_layer(\"block2_conv2\").output\n",
    "    s3 = vgg19.get_layer(\"block3_conv4\").output\n",
    "    s4 = vgg19.get_layer(\"block4_conv4\").output\n",
    "\n",
    "    f1 = FFM(s1, s2, 64)\n",
    "    f2 = FFM(s2, s3, 128)\n",
    "    f3 = FFM(s3, s4, 256)\n",
    "\n",
    "    # d1 = decoder_block(s5, f4, 512)\n",
    "    d2 = decoder_block(s4, f3, 256)\n",
    "    d3 = decoder_block(d2, f2, 128)\n",
    "    \n",
    "    x1 = UpSampling2D(size=(2, 2))(d3)\n",
    "    # siem = SIEM(x1, f1, 64, 2)\n",
    "    combined = Concatenate()([x1, f1])\n",
    "    print(combined)\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(combined)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"VGG19_U-Net\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ResNet Model\n",
    "input_shape = (256, 256, 3)\n",
    "base_model = build_vgg19_unet(input_shape)\n",
    "# img_shape = (299, 299, 3)\n",
    "# base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dropout(rate=0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(rate=0.25),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adamax(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(tr_gen, epochs=10, validation_data=valid_gen, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc = hist.history['accuracy']\n",
    "tr_loss = hist.history['loss']\n",
    "tr_per = hist.history['precision']\n",
    "tr_recall = hist.history['recall']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "val_loss = hist.history['val_loss']\n",
    "val_per = hist.history['val_precision']\n",
    "val_recall = hist.history['val_recall']\n",
    "\n",
    "# Visualizing the metrics\n",
    "Epochs = [i + 1 for i in range(len(tr_acc))]\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(Epochs, tr_loss, 'r', label='Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "# Similar plots for accuracy, precision, recall...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(tr_gen, verbose=1)\n",
    "valid_score = model.evaluate(valid_gen, verbose=1)\n",
    "test_score = model.evaluate(ts_gen, verbose=1)\n",
    "\n",
    "print(f\"Train Loss: {train_score[0]:.4f}\")\n",
    "print(f\"Train Accuracy: {train_score[1]*100:.2f}%\")\n",
    "print('-' * 20)\n",
    "\n",
    "# Predict and generate confusion matrix\n",
    "preds = model.predict(ts_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "cm = confusion_matrix(ts_gen.classes, y_pred)\n",
    "labels = list(class_dict.keys())\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('Truth Label')\n",
    "plt.show()\n",
    "\n",
    "clr = classification_report(ts_gen.classes, y_pred)\n",
    "print(clr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    label = list(class_dict.keys())\n",
    "    img = Image.open(img_path)\n",
    "    resized_img = img.resize((256, 256))\n",
    "    img = np.asarray(resized_img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255\n",
    "    predictions = model.predict(img)\n",
    "    probs = list(predictions[0])\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(resized_img)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars = plt.barh(label, probs)\n",
    "    plt.xlabel('Probability', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "# Predict for an image\n",
    "predict('Testing/glioma/Te-glTr_0000.jpg')\n",
    "predict('Testing/meningioma/Te-meTr_0003.jpg')\n",
    "predict('Testing/pituitary/Te-piTr_0003.jpg')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
